{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886510df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config OK. Runs will be saved under: c:\\Users\\Shravya H Jain\\Downloads\\_Law_\\Nyaya_Samiti\\model\\runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shravya H Jain\\Downloads\\_Law_\\Nyaya_Samiti\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected file: C:\\Users\\Shravya H Jain\\Downloads\\_Law_\\Nyaya_Samiti\\model\\Screenshot 2025-09-02 161457.png\n",
      "Saved to: c:\\Users\\Shravya H Jain\\Downloads\\_Law_\\Nyaya_Samiti\\model\\runs\\run-20250902-161619\n",
      "\n",
      "--- RAW OCR (first 500 chars) ---\n",
      " se . 3g OQ?ee le 5\n",
      "PSEELETLE ches\n",
      "os 8 & SF o a\n",
      "Se 8 Roee FEE\n",
      "ev FE RE pit ee EE\n",
      "ECU 8s Fe Borge\n",
      "BPRS ha ghee GF\n",
      "RF Teger FRey\n",
      "\"eUdibech frog\n",
      "ee Ss gba g.& &\n",
      "i ebst EF Lbs |\n",
      "OB BE tog ยง rag\n",
      "& Pe os\n",
      "\n",
      "\n",
      "--- GEMINI CLEAN TEXT (first 500 chars) ---\n",
      " Multi-layer Perceptron\n",
      "\n",
      "Artificial Neural Networks is especially is used for\n",
      "in application such as handwritten recognition,\n",
      "learning to recognize spoken words, learning\n",
      "to recognize faces.\n",
      "\n",
      "Artificial neural network has been inspired in\n",
      "part by the observation that biological learning systems\n",
      "(brain) are built of very complex webs of\n",
      "interconnected neurons. Similar way, artificial\n",
      "neural network are built out of a densely\n",
      "interconnected set of simple units, where each\n",
      "unit takes a number of Rea\n",
      "\n",
      "--- ENTITIES JSON (first 500 chars) ---\n",
      " ```json\n",
      "{\n",
      "  \"names\": [],\n",
      "  \"ids\": [],\n",
      "  \"dates\": [],\n",
      "  \"addresses\": [],\n",
      "  \"emails\": [],\n",
      "  \"phones\": [],\n",
      "  \"stamps_or_seals\": []\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import json, time\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "assert GEMINI_API_KEY != \"\", \"Please set GEMINI_API_KEY (env var or .env).\"\n",
    "\n",
    "# If on Windows, set tesseract.exe path here:\n",
    "TESSERACT_CMD = r\"C:/Program Files/Tesseract-OCR/tesseract.exe\"\n",
    "\n",
    "OCR_LANGS = \"eng+hin\"\n",
    "RUNS_DIR = \"runs\"\n",
    "os.makedirs(RUNS_DIR, exist_ok=True)\n",
    "print(\"Config OK. Runs will be saved under:\", os.path.abspath(RUNS_DIR))\n",
    "\n",
    "if TESSERACT_CMD:\n",
    "    pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "def deskew(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bitwise_not(gray)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    coords = np.column_stack(np.where(thresh > 0))\n",
    "    if len(coords) < 5:\n",
    "        return image\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "def preprocess_for_ocr(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    assert img is not None, f\"Could not read image at {img_path}\"\n",
    "    img = deskew(img)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    den = cv2.fastNlMeansDenoising(gray, None, h=15, templateWindowSize=7, searchWindowSize=21)\n",
    "    thr = cv2.adaptiveThreshold(den, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 10)\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    morphed = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    return morphed\n",
    "\n",
    "def tesseract_ocr(image_np, psm=6, oem=3, lang=OCR_LANGS):\n",
    "    config = f\"--oem {oem} --psm {psm}\"\n",
    "    text = pytesseract.image_to_string(image_np, lang=lang, config=config)\n",
    "    return text\n",
    "\n",
    "def run_gemini_repair(image_path, raw_text, prompt_mode=\"clean\"):\n",
    "    \"\"\"\n",
    "    prompt_mode:\n",
    "      - \"clean\": produce clean reconstructed text using both inputs.\n",
    "      - \"extract\": return structured fields (entities) as JSON.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "    base_system_prompt = (\n",
    "        \"You are an expert OCR post-processor. \"\n",
    "        \"You are given (1) an original document image and (2) noisy OCR text from Tesseract.\\n\"\n",
    "        \"Task: reconstruct the most accurate text you can. \"\n",
    "        \"Preserve reading order, headers, tables (as Markdown), and line breaks. \"\n",
    "        \"If handwriting is present, read from the image to fill missing/incorrect words. \"\n",
    "        \"Do not invent content that is not visible in the image.\"\n",
    "    )\n",
    "    extract_system_prompt = (\n",
    "        \"Extract key fields from the document. Respond with strict JSON only. \"\n",
    "        \"Use keys: 'names', 'ids', 'dates', 'addresses', 'emails', 'phones', 'stamps_or_seals'. \"\n",
    "        \"When unknown, use null or empty arrays. Do not include any commentary.\"\n",
    "    )\n",
    "    user_prompt = extract_system_prompt if prompt_mode == \"extract\" else base_system_prompt\n",
    "    img = Image.open(image_path)\n",
    "    resp = model.generate_content([\n",
    "        {\"text\": user_prompt},\n",
    "        img,\n",
    "        {\"text\": \"-----\\nOCR (Tesseract) text:\\n\" + str(raw_text) + \"\\n-----\\n\"}\n",
    "    ])\n",
    "    return resp.text.strip()\n",
    "\n",
    "def save_run(run_dir, settings, raw_text, gemini_text, entities_json_str=None):\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    with open(os.path.join(run_dir, \"settings.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(settings, f, ensure_ascii=False, indent=2)\n",
    "    with open(os.path.join(run_dir, \"raw_ocr.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(raw_text or \"\")\n",
    "    with open(os.path.join(run_dir, \"gemini_text.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(gemini_text or \"\")\n",
    "    if entities_json_str:\n",
    "        with open(os.path.join(run_dir, \"entities.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(entities_json_str)\n",
    "    print(\"Saved to:\", os.path.abspath(run_dir))\n",
    "    return os.path.abspath(run_dir)\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "image_path = input(\"Please enter the path to your image file: \")\n",
    "\n",
    "if not image_path:\n",
    "    raise ValueError(\"No image path provided!\")\n",
    "\n",
    "print(f\"Selected file: {image_path}\")\n",
    "\n",
    "# Run your pipeline\n",
    "pre = preprocess_for_ocr(image_path)\n",
    "raw_text = tesseract_ocr(pre, psm=6, oem=3)\n",
    "gemini_text = run_gemini_repair(image_path, raw_text, prompt_mode=\"clean\")\n",
    "\n",
    "DO_EXTRACT = True\n",
    "entities_json_str = None\n",
    "if DO_EXTRACT:\n",
    "    entities_json_str = run_gemini_repair(image_path, raw_text, prompt_mode=\"extract\")\n",
    "\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "run_dir = os.path.join(RUNS_DIR, f\"run-{ts}\")\n",
    "settings = {\n",
    "    \"languages\": OCR_LANGS,\n",
    "    \"tesseract_cmd\": TESSERACT_CMD,\n",
    "    \"psm\": 6,\n",
    "    \"oem\": 3,\n",
    "    \"model\": \"gemini-2.5-flash\",\n",
    "    \"prompt_modes\": [\"clean\", \"extract\" if DO_EXTRACT else \"clean\"],\n",
    "    \"image_path\": image_path,\n",
    "}\n",
    "save_run(run_dir, settings, raw_text, gemini_text, entities_json_str)\n",
    "\n",
    "print(\"\\n--- RAW OCR (first 500 chars) ---\\n\", (raw_text or \"\")[:500])\n",
    "print(\"\\n--- GEMINI CLEAN TEXT (first 500 chars) ---\\n\", (gemini_text or \"\")[:500])\n",
    "if entities_json_str:\n",
    "    print(\"\\n--- ENTITIES JSON (first 500 chars) ---\\n\", entities_json_str[:500])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
